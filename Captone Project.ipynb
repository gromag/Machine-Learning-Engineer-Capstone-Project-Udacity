{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: This is a great title. \n",
    "author: Author Name\n",
    "abstract: This is a great abstract\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .warn {\n",
       "        color: red;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<style>\n",
    "    .warn {\n",
    "        color: red;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unintended Bias in toxicity classification\n",
    "\n",
    "## Udacity Machine Learning Engineer Nanodegree\n",
    "\n",
    "- _Author: Giuseppe Romagnuolo_\n",
    "- _Project from the Kaggle competition: [Jigsaw unintended bias in toxicity classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview)_\n",
    "- _Field: Natural Language Processing_<br/>\n",
    "\n",
    "\n",
    "\n",
    "## Definition\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "_Student provides a high-level overview of the project in layman’s terms. Background information such as the problem domain, the project origin, and related data sets or input data is given._\n",
    "\n",
    "Natural Language Processing is a complex field which is hypothesised to be part of AI-complete set of problems, implying that the difficulty of these computational problems is equivalent to that of solving the central artificial intelligence problem making computers as intelligent as people.[$^{[cit.Wikipedia]}$](https://en.wikipedia.org/wiki/AI-complete)\n",
    "\n",
    "With over 90% of data ever generated being produced in the last 2 years[$^{[ref.ScienceDaily]}$](https://www.sciencedaily.com/releases/2013/05/130522085217.htm) and with a great proportion being human generated unstructured text there is an ever increasing need to advance the field of Natural Language Processing.\n",
    "\n",
    "Recent UK Government proposal to have measures to regulate social media companies over harmful content, including \"substantial\" fines and the ability to block services that do not stick to the rules is an example of the regulamentory need to better manage the content that is being generated by users. [$^{[ref.BBC]}$](https://www.bbc.co.uk/news/technology-47135058)\n",
    "\n",
    "Other initiatives like [Riot Games](https://www.riotgames.com/en)'s work aimed to predict and reform toxic player behaviour during games[$^{[ref.ArsTechnica]}$](https://arstechnica.com/gaming/2013/05/using-science-to-reform-toxic-player-behavior-in-league-of-legends/) is another example of this effort to understand the content being generated by users and moderate toxic content.\n",
    "\n",
    "However, as highlighted by the Kaggle competition [Jigsaw unintended bias in toxicity classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview), existing models suffer from unintended bias where models might predict high likelihood of toxicity for content containing certain words (e.g. \"gay\") even when those comments were not actually toxic (such as \"I am a gay woman\"), leaving  machine only classification models still sub-standard.\n",
    "\n",
    "Having tools that are able to flag up toxic content without suffering from unintended bias is of paramount importance to preserve Internet's fairness and freedom of speech.\n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "_The problem which needs to be solved is clearly defined. <span class=\"warn\">A strategy for solving the problem, including discussion of the expected solution, has been made.</span>_\n",
    "\n",
    "From [Kaggle](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview) competition page:\n",
    "\n",
    "The Conversation AI team, a research initiative founded by Jigsaw and Google (both part of Alphabet), builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion.\n",
    "\n",
    "Last year, in the Toxic Comment Classification Challenge, participants built multi-headed models to recognize toxicity and several subtypes of toxicity. This year's competition is a related challenge: building toxicity models that operate fairly across a diverse range of conversations.\n",
    "\n",
    "Here’s the background: When the Conversation AI team first built toxicity models, they found that the models incorrectly learned to associate the names of frequently attacked identities with toxicity. Models predicted a high likelihood of toxicity for comments containing those identities (e.g. \"gay\"), even when those comments were not actually toxic (such as \"I am a gay woman\"). This happens because training data was pulled from available sources where unfortunately, certain identities are overwhelmingly referred to in offensive ways. Training a model from data with these imbalances risks simply mirroring those biases back to users.\n",
    "\n",
    "In this competition, you're challenged to build a model that recognizes toxicity and minimizes this type of unintended bias with respect to mentions of identities. You'll be using a dataset labeled for identity mentions and optimizing a metric designed to measure unintended bias. Develop strategies to reduce unintended bias in machine learning models, and you'll help the Conversation AI team, and the entire industry, build models that work well for a wide range of conversations.\n",
    "\n",
    "\n",
    "### Metrics\n",
    "\n",
    "Metrics used to measure performance of a model or result are clearly defined. Metrics are justified based on the characteristics of the problem.\n",
    "\n",
    "## Analysis\n",
    "\n",
    "### Data Exploration\n",
    "\n",
    "If a dataset is present, features and calculated statistics relevant to the problem have been reported and discussed, along with a sampling of the data. In lieu of a dataset, a thorough description of the input space or input data has been made. Abnormalities or characteristics about the data or input that need to be addressed have been identified.\n",
    "\n",
    "### Exploratory Visualization\n",
    "\n",
    "A visualization has been provided that summarizes or extracts a relevant characteristic or feature about the dataset or input data with thorough discussion. Visual cues are clearly defined.\n",
    "\n",
    "### Algorithms and Techniques\n",
    "\n",
    "Algorithms and techniques used in the project are thoroughly discussed and properly justified based on the characteristics of the problem.\n",
    "\n",
    "### Benchmark\n",
    "\n",
    "Student clearly defines a benchmark result or threshold for comparing performances of solutions obtained.\n",
    "\n",
    "\n",
    "## Methodology\n",
    "\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "All preprocessing steps have been clearly documented. Abnormalities or characteristics about the data or input that needed to be addressed have been corrected. If no data preprocessing is necessary, it has been clearly justified.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The process for which metrics, algorithms, and techniques were implemented with the given datasets or input data has been thoroughly documented. Complications that occurred during the coding process are discussed.\n",
    "\n",
    "### Refinement\n",
    "\n",
    "The process of improving upon the algorithms and techniques used is clearly documented. Both the initial and final solutions are reported, along with intermediate solutions, if necessary.\n",
    "\n",
    "## Results\n",
    "\n",
    "### Model Evaluation and Validation\n",
    "\n",
    "The final model’s qualities — such as parameters — are evaluated in detail. Some type of analysis is used to validate the robustness of the model’s solution.\n",
    "\n",
    "### Justification\n",
    "\n",
    "The final results are compared to the benchmark result or threshold with some type of statistical analysis. Justification is made as to whether the final model and solution is significant enough to have adequately solved the problem.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "### Free-Form Visualization\n",
    "\n",
    "A visualization has been provided that emphasizes an important quality about the project with thorough discussion. Visual cues are clearly defined.\n",
    "\n",
    "### Reflection\n",
    "\n",
    "Student adequately summarizes the end-to-end problem solution and discusses one or two particular aspects of the project they found interesting or difficult.\n",
    "\n",
    "### Improvement\n",
    "\n",
    "Discussion is made as to how one aspect of the implementation could be improved. Potential solutions resulting from these improvements are considered and compared/contrasted to the current solution.\n",
    "\n",
    "## Quality\n",
    "\n",
    "### Presentation\n",
    "\n",
    "Project report follows a well-organized structure and would be readily understood by its intended audience. Each section is written in a clear, concise and specific manner. Few grammatical and spelling mistakes are present. All resources used to complete the project are cited and referenced.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
